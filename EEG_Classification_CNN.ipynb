{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HannaCarla/HannaCarla/blob/main/Imbalanced_MixedModel_cw1_2107.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9SoPYHC_HCE"
      },
      "outputs": [],
      "source": [
        "!pip install mne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y45a34oKhU0-"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling2D, Flatten, Dense\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lX2BHTSoLO6"
      },
      "outputs": [],
      "source": [
        "iir_params=dict(order=2, ftype='butter')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes = []"
      ],
      "metadata": {
        "id": "JcGCrmIg57q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processamento dos dados"
      ],
      "metadata": {
        "id": "vTGg0wnxFDLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "QO1VCxOtFHVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read all file\n",
        "all_files_path=glob('/content/drive/MyDrive/Hanna/Mix_Pacientes/imb_mixed_model_files/new_sample/*.edf')\n",
        "print((all_files_path))"
      ],
      "metadata": {
        "id": "2wzcHCDDy2-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_files_path"
      ],
      "metadata": {
        "id": "SrBwoxfhfK5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onMP56AroLO6"
      },
      "outputs": [],
      "source": [
        "def preprocessing(file_path):\n",
        "    datax=mne.io.read_raw_edf(file_path,preload=True)\n",
        "    datax.set_eeg_reference()\n",
        "    datax.filter(1., None)\n",
        "    datax.pick_channels(['F3-C3','C3-P3', 'F4-C4','C4-P4' ])\n",
        "    datax.filter(None, h_freq=40.0, method='iir', iir_params=iir_params, verbose=True)\n",
        "    epochs=mne.make_fixed_length_epochs(datax,duration=4)\n",
        "    epochs=epochs.to_data_frame()\n",
        "    return epochs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[preprocessing(subject) for subject in all_files_path]"
      ],
      "metadata": {
        "id": "2GXzPa9cDIQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data))"
      ],
      "metadata": {
        "id": "rHSTNMmphD7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = data[0]\n",
        "df2 = data[1]\n",
        "df3 = data[2]\n",
        "df4 = data[3]\n",
        "df5 = data[4]\n",
        "df6 = data[5]"
      ],
      "metadata": {
        "id": "izuIwHPrvkPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes = [df1, df2, df3, df4, df5, df6]"
      ],
      "metadata": {
        "id": "O_RhlXpEBr7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Função organizar dataframes\n",
        "for i, df in enumerate (dataframes):\n",
        "  df['condition'] = 0\n",
        "  df['registro'] = i + 1\n"
      ],
      "metadata": {
        "id": "eEjImWRIDZPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df=pd.concat([df1, df2, df3, df4, df5, df6])"
      ],
      "metadata": {
        "id": "HIi-XJ_zj0yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df.info()"
      ],
      "metadata": {
        "id": "P2qtYzUVkJtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reindex the columns\n",
        "all_df = all_df.reindex(columns=['time', 'condition', 'epoch', 'registro', 'F3-C3', 'C3-P3', 'F4-C4', 'C4-P4'])\n",
        "\n",
        "print(all_df)"
      ],
      "metadata": {
        "id": "NQF3lYB-lHXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Labels"
      ],
      "metadata": {
        "id": "ceEMgCZ2l4BW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seizureepochs (start_time, duration):\n",
        "  start_time = start_time  # example seizure start time in seconds\n",
        "  duration = duration  # example seizure duration in seconds\n",
        "  sampling_rate = 256  # EEG data sampling rate in Hz\n",
        "  epoch_len = 4  # epoch length in seconds\n",
        "  overlap = 0  # epoch overlap in seconds\n",
        "  epoch_len_samples = epoch_len * sampling_rate  # epoch length in data points\n",
        "  overlap_samples = overlap * sampling_rate  # epoch overlap in data points\n",
        "  start_sample = int((start_time - overlap) * sampling_rate)  # calculate starting sample index\n",
        "  end_sample = int((start_time + duration - overlap) * sampling_rate)  # calculate ending sample index\n",
        "  start_epoch = int(round(start_sample / epoch_len_samples))  # round to nearest epoch boundary\n",
        "  end_epoch = int(round(end_sample / epoch_len_samples))  # round to nearest epoch boundary\n",
        "  seizure_epochs = list(range(start_epoch, end_epoch))  # create list of epochs that correspond to seizure\n",
        "  return seizure_epochs\n"
      ],
      "metadata": {
        "id": "nK-pHqxeIrCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Registro chb01_26"
      ],
      "metadata": {
        "id": "O95snC8AhyFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "registrochb01_26 = seizureepochs(1862, 101)"
      ],
      "metadata": {
        "id": "p-LRRPaThyFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "registrochb01_26"
      ],
      "metadata": {
        "id": "FiIAneqUhyFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df.loc[(all_df['epoch']>=465) & (all_df['epoch']<=489) & (all_df['registro']==1), 'condition']=1"
      ],
      "metadata": {
        "id": "o8vbie9jHUtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df['condition'].value_counts()"
      ],
      "metadata": {
        "id": "kkafMoOqhyFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Registro chb03_03"
      ],
      "metadata": {
        "id": "9NVNB2DrqFRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "registrochb03_03 =seizureepochs(432, 69)"
      ],
      "metadata": {
        "id": "f_WHSP8Zr2NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "registrochb03_03"
      ],
      "metadata": {
        "id": "ojNeAmbgr-fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df.loc[(all_df['epoch']>=107) & (all_df['epoch']<=123) & (all_df['registro']==6), 'condition']=1"
      ],
      "metadata": {
        "id": "UyiOSoUzHbtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df['condition'].value_counts()"
      ],
      "metadata": {
        "id": "PGIY_Fqrqf27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Registro chb05_17"
      ],
      "metadata": {
        "id": "yjereadHcoNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Registro_chb05_17 = seizureepochs(2451, 120)"
      ],
      "metadata": {
        "id": "gopf5jn0coNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Registro_chb05_17"
      ],
      "metadata": {
        "id": "l4CH9SQxcoNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df.loc[(all_df['epoch']>=612) & (all_df['epoch']<=641) & (all_df['registro']==2), 'condition']=1"
      ],
      "metadata": {
        "id": "oH8gpeHLHgVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df['condition'].value_counts()"
      ],
      "metadata": {
        "id": "HUOZj9SucoNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Registro Chb08_21"
      ],
      "metadata": {
        "id": "fdVu44J4dBPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Registro_Chb08_21 = seizureepochs(2083, 264)"
      ],
      "metadata": {
        "id": "JDas6-HndBPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Registro_Chb08_21"
      ],
      "metadata": {
        "id": "TaPH2vDDdBPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df.loc[(all_df['epoch']>=520) & (all_df['epoch']<=585) & (all_df['registro']==5), 'condition']=1"
      ],
      "metadata": {
        "id": "FEEsg6IiHj-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df['condition'].value_counts()"
      ],
      "metadata": {
        "id": "sy9WgczUdBPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Registro Chb11_99"
      ],
      "metadata": {
        "id": "YZX9zFl0jNMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Registro_Chb11_99 = seizureepochs(1454, 752)"
      ],
      "metadata": {
        "id": "BhONrFvejNMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Registro_Chb11_99"
      ],
      "metadata": {
        "id": "pYK0uLohjNMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df.loc[(all_df['epoch']>=363) & (all_df['epoch']<=550) & (all_df['registro']==3), 'condition']=1"
      ],
      "metadata": {
        "id": "cDeiOO4rHrN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df['condition'].value_counts()"
      ],
      "metadata": {
        "id": "olY7ICJRjNM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Registro Chb02_16"
      ],
      "metadata": {
        "id": "oq8m6Tn_9tmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "registrochb02_16 = seizureepochs(130, 82)"
      ],
      "metadata": {
        "id": "j_Dg8c479x30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "registrochb02_16"
      ],
      "metadata": {
        "id": "WDPAarYr9-bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df.loc[(all_df['epoch']>=31) & (all_df['epoch']<=51) & (all_df['registro']==4), 'condition']=1"
      ],
      "metadata": {
        "id": "rZsgJ-Gj-Cfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df['condition'].value_counts()"
      ],
      "metadata": {
        "id": "ShWzn0Dj-Jtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#verificar se as labels foram inseridas\n",
        "unique_values = np.unique(all_df['condition'])\n",
        "print(unique_values)\n"
      ],
      "metadata": {
        "id": "xCPCp7f0xUv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Transformation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BdmhTVBWId2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "XTZc_As0xlQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_array(array, chunk_size):\n",
        "    rows, cols = array.shape\n",
        "    num_chunks = rows // chunk_size\n",
        "    chunks = np.split(array[:num_chunks*chunk_size], num_chunks)\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "6rw4Uz30lA1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "channel_columns_names = all_df.columns[4:]\n",
        "frame_length = 256\n",
        "\n",
        "frames = [\n",
        "    frame for frame in tqdm(split_array(all_df, frame_length))\n",
        "    if frame['condition'].unique().shape[0] == 1 and frame['epoch'].unique().shape[0] == 1\n",
        "]\n",
        "\n",
        "print(f'Generated {len(frames)} frames')\n",
        "\n",
        "frames_X = np.array([frame[channel_columns_names].values for frame in tqdm(frames) if frame.shape[0] == frame_length])\n",
        "frames_Y = np.array([frame['condition'].unique()[0] for frame in tqdm(frames) if frame.shape[0] == frame_length])"
      ],
      "metadata": {
        "id": "FFdjRsMy4wrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Test Split\n",
        "\n"
      ],
      "metadata": {
        "id": "HHVraUNVEHQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(frames_X, frames_Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# split the training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "XDDZzJqQEHQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_train', X_train.shape)\n",
        "print('y_train', y_train.shape)\n",
        "print('X_test', X_test.shape)\n",
        "print('y_test', y_test.shape)\n",
        "print('X_val',X_val.shape)\n",
        "print('y_val', y_val.shape)"
      ],
      "metadata": {
        "id": "V0JlntZAEHRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame([pd.Series(data).value_counts(normalize=True) for data in (y_train, y_test, y_val)], index=['Train', 'Test', 'Val'])"
      ],
      "metadata": {
        "id": "XiPS7qH7EHRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning"
      ],
      "metadata": {
        "id": "pa5ZUx0eV5uN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, DepthwiseConv2D, BatchNormalization, Activation, AveragePooling2D, Flatten, Dense\n",
        "\n",
        "# Define the input shape\n",
        "# num_epochs = 900\n",
        "# num_channels = 4\n",
        "# num_samples = 1024\n",
        "\n",
        "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "\n",
        "# Reshape the input data\n",
        "# X_train_reshaped = X_train.reshape(-1, num_channels, 1)\n",
        "# X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
        "\n",
        "X_train_reshaped = X_train.reshape(*X_train.shape, 1)\n",
        "X_val_reshaped = X_val.reshape(*X_val.shape, 1)\n",
        "X_test_reshaped = X_test.reshape(*X_test.shape, 1)"
      ],
      "metadata": {
        "id": "1u-Jnc8aZqPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_reshaped.shape"
      ],
      "metadata": {
        "id": "aY2vkl4KhhfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def EEGNet2(input_shape, num_classes):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # First Conv2D layer\n",
        "    conv1 = Conv2D(filters=16, kernel_size=(64, 1), strides=(1, 1), padding='same', data_format='channels_last',\n",
        "                   kernel_regularizer=l2(0.01))(input_layer)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = DepthwiseConv2D(kernel_size=(2, 1), strides=(2, 2), depth_multiplier=1, padding='valid')(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Activation('elu')(conv1)\n",
        "\n",
        "    # Second Conv2D layer\n",
        "    conv2 = Conv2D(filters=32, kernel_size=(32, 1), strides=(1, 1), padding='same', data_format='channels_last',\n",
        "                   kernel_regularizer=l2(0.01))(conv1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = DepthwiseConv2D(kernel_size=(2, 1), strides=(2, 2), depth_multiplier=2, padding='valid')(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Activation('elu')(conv2)\n",
        "\n",
        "    # Third Conv2D layer\n",
        "    conv3 = Conv2D(filters=32, kernel_size=(16, 1), strides=(1, 1), padding='same', data_format='channels_last',\n",
        "                   kernel_regularizer=l2(0.01))(conv2)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = DepthwiseConv2D(kernel_size=(2, 1), strides=(2, 2), depth_multiplier=4, padding='valid')(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Activation('elu')(conv3)\n",
        "\n",
        "    # Average Pooling layer\n",
        "    avg_pool = AveragePooling2D(pool_size=(4, 1), strides=(1, 1))(conv3)\n",
        "\n",
        "    # Flatten layer\n",
        "    flatten = Flatten()(avg_pool)\n",
        "\n",
        "    # Dense layer with L2 regularization\n",
        "    dense = Dense(units=num_classes, activation='sigmoid', kernel_regularizer=l2(0.01))(flatten)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=input_layer, outputs=dense)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "4XsVLvi94bL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = EEGNet(input_shape=(900, 4, 1024, 1), num_classes=1)\n",
        "model = EEGNet2(input_shape=(256, 4, 1), num_classes=1)\n",
        "history = model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6o03ajS8vgLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "4dGOChfMIwnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DL+KFold"
      ],
      "metadata": {
        "id": "lc9Xy4v9V6yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from statistics import mean\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import balanced_accuracy_score, accuracy_score, precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "5vaTnJTWtpLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate class weights\n",
        "class_weight = {0: 1, 1: 20}  # Define the class weights manually"
      ],
      "metadata": {
        "id": "rV39XwLZPPP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_accu_stratified_nm = []\n",
        "cnn_precision_0 = []\n",
        "cnn_precision_1 = []\n",
        "cnn_recall_0 = []\n",
        "cnn_recall_1 = []\n",
        "cnn_f1_0 = []\n",
        "cnn_f1_1 = []\n",
        "models = []\n",
        "loss_values = []\n",
        "fold_num = 1\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "for train_index, test_index in skf.split(X_train_reshaped, y_train):\n",
        "\n",
        "    X_train_fold, X_val_fold = X_train_reshaped[train_index], X_train_reshaped[test_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n",
        "\n",
        "    # model = EEGNet(input_shape=(900, 4, 1024, 1), num_classes=1)\n",
        "    model = EEGNet2(input_shape=(256, 4, 1), num_classes=1)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(X_train_fold, y_train_fold, class_weight=class_weight)\n",
        "    y_pred = model.predict(X_val_fold)\n",
        "    y_pred_bin = (y_pred > 0.5).astype(int)\n",
        "\n",
        "    accuracy = accuracy_score(y_val_fold, y_pred_bin)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_val_fold, y_pred_bin, average=None)\n",
        "\n",
        "    cnn_accu_stratified_nm.append(accuracy)\n",
        "    cnn_precision_0.append(precision[0])\n",
        "    cnn_precision_1.append(precision[1])\n",
        "    cnn_recall_0.append(recall[0])\n",
        "    cnn_recall_1.append(recall[1])\n",
        "    cnn_f1_0.append(f1[0])\n",
        "    cnn_f1_1.append(f1[1])\n",
        "    models.append(model)\n",
        "    loss_values.append(history.history['loss'])\n",
        "\n",
        "    print(f\"Fold {fold_num}: Accuracy={accuracy:.4f}, Precision (class 0)={precision[0]:.4f}, Precision (class 1)={precision[1]:.4f}, Recall (class 0)={recall[0]:.4f}, Recall (class 1)={recall[1]:.4f}, F1-score (class 0)={f1[0]:.4f}, F1-score (class 1)={f1[1]:.4f}\")\n",
        "    fold_num += 1\n",
        "\n",
        "# Create a dictionary to hold the results\n",
        "results = {\n",
        "    'Fold': range(1, fold_num),\n",
        "    'Accuracy': cnn_accu_stratified_nm,\n",
        "    'Precision (Class 0)': cnn_precision_0,\n",
        "    'Precision (Class 1)': cnn_precision_1,\n",
        "    'Recall (Class 0)': cnn_recall_0,\n",
        "    'Recall (Class 1)': cnn_recall_1,\n",
        "    'F1-score (Class 0)': cnn_f1_0,\n",
        "    'F1-score (Class 1)': cnn_f1_1\n",
        "}\n",
        "# Convert the dictionary to a DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Calculate overall statistics\n",
        "overall_accuracy = df['Accuracy'].mean()\n",
        "overall_precision_0 = df['Precision (Class 0)'].mean()\n",
        "overall_precision_1 = df['Precision (Class 1)'].mean()\n",
        "overall_recall_0 = df['Recall (Class 0)'].mean()\n",
        "overall_recall_1 = df['Recall (Class 1)'].mean()\n",
        "overall_f1_0 = df['F1-score (Class 0)'].mean()\n",
        "overall_f1_1 = df['F1-score (Class 1)'].mean()\n",
        "\n",
        "# Print the table and overall statistics\n",
        "print(df)\n",
        "print('Maximum Accuracy:', df['Accuracy'].max())\n",
        "print('Minimum Accuracy:', df['Accuracy'].min())\n",
        "print('Overall Accuracy:', overall_accuracy)\n",
        "print('Overall Precision (class 0):', overall_precision_0)\n",
        "print('Overall Precision (class 1):', overall_precision_1)\n",
        "print('Overall Recall (class 0):', overall_recall_0)\n",
        "print('Overall Recall (class 1):', overall_recall_1)\n",
        "print('Overall F1-score (class 0):', overall_f1_0)\n",
        "print('Overall F1-score (class 1):', overall_f1_1)\n"
      ],
      "metadata": {
        "id": "IMhNqc-LKUVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fold_01=models[0]\n",
        "model_fold_02=models[1]\n",
        "model_fold_03=models[2]\n",
        "model_fold_04=models[3]\n",
        "model_fold_05=models[4]\n",
        "model_fold_06=models[5]\n",
        "model_fold_07=models[6]\n",
        "model_fold_08=models[7]\n",
        "model_fold_09=models[8]\n",
        "model_fold_10=models[9]"
      ],
      "metadata": {
        "id": "FVqS2yZwL9i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation + check overfitting"
      ],
      "metadata": {
        "id": "CBbvIl7Y6LbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain predictions on the test data\n",
        "y_pred_test = model_fold_01.predict(X_test_reshaped)\n",
        "y_pred_test_bin = (y_pred_test > 0.5).astype(int)\n",
        "\n",
        "# Evaluate performance metrics on the test data\n",
        "accuracy_test = accuracy_score(y_test, y_pred_test_bin)\n",
        "precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_pred_test_bin, average=None)\n",
        "\n",
        "print(f\"Test set: Accuracy={accuracy_test:.4f}, Precision (class 0)={precision_test[0]:.4f}, Precision (class 1)={precision_test[1]:.4f}, Recall (class 0)={recall_test[0]:.4f}, Recall (class 1)={recall_test[1]:.4f}, F1-score (class 0)={f1_test[0]:.4f}, F1-score (class 1)={f1_test[1]:.4f}\")\n"
      ],
      "metadata": {
        "id": "g9ijmJ46njUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate precision and recall values\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_test)\n",
        "\n",
        "# Find indices for positive class (class 1)\n",
        "positive_class_index = np.where(y_test == 1)[0]\n",
        "\n",
        "# Calculate average precision\n",
        "average_precision = average_precision_score(y_test, y_pred_test)\n",
        "\n",
        "# Plot precision-recall curve for positive class\n",
        "plt.plot(recall[positive_class_index], precision[positive_class_index], label=f'Avg Precision = {average_precision:.2f})')\n",
        "\n",
        "# Set the x and y axis limits\n",
        "plt.xlim([0.0, 1.05])\n",
        "plt.ylim([0.0, 1.05])\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "# Add a diagonal line for reference\n",
        "plt.plot([1, 0], [0, 1], 'k--')\n",
        "\n",
        "\n",
        "#Adcionar linhas de grade\n",
        "plt.grid()\n",
        "\n",
        "# Show the plot\n",
        "plt.legend(loc='lower left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WJ0bem9C8yDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate the ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_test, pos_label=1)\n",
        "\n",
        "# Calculate the AUC score\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "\n",
        "# Set the x and y axis limits\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "\n",
        "#Adcionar linhas de grade\n",
        "plt.grid()\n",
        "\n",
        "# Add a diagonal line for reference\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "# Show the legend and plot\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UY8rzPO8BtiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "gA1IwieIQQH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test_bin).ravel()\n",
        "\n",
        "print(\"True Negative:\", tn)\n",
        "print(\"False Positive:\", fp)\n",
        "print(\"False Negative:\", fn)\n",
        "print(\"True Positive:\", tp)"
      ],
      "metadata": {
        "id": "1Tc_olAWQT7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pred_test_bin)"
      ],
      "metadata": {
        "id": "5414i8c_R8gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "f72iMOLmSztg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Update confusion matrix\n",
        "conf_mat = confusion_matrix(y_test, y_pred_test_bin)\n",
        "conf_mat_norm = conf_mat / conf_mat.sum(axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "Q3DKo_3nSF_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "# define the colormap\n",
        "cmap = plt.cm.Blues\n",
        "\n",
        "# plot the confusion matrix\n",
        "plt.imshow(conf_mat_norm, interpolation='nearest', cmap=cmap)\n",
        "plt.colorbar()\n",
        "\n",
        "# add labels to the plot\n",
        "tick_marks = np.arange(2)\n",
        "plt.xticks(tick_marks, ['Interictal', 'Ictal'], rotation=45)\n",
        "plt.yticks(tick_marks, ['Interictal', 'Ictal'])\n",
        "\n",
        "# add sample counts to the plot\n",
        "thresh = conf_mat_norm.max() / 2.\n",
        "for i, j in itertools.product(range(conf_mat_norm.shape[0]), range(conf_mat_norm.shape[1])):\n",
        "    plt.text(j, i, format(conf_mat_norm[i, j], '.2f'),\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if conf_mat_norm[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "C81zuyTdUSsj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
